





# !pip install sumy


import nltk

nltk.download("punkt")


from sumy.parsers.html import HtmlParser
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer as Summarizer
from sumy.nlp.stemmers import Stemmer
from sumy.utils import get_stop_words


LANGUAGE = "chinese"
# LANGUAGE = "english"
SENTENCES_COUNT = 5
# SENTENCES_COUNT = 10
url = "https://news.ltn.com.tw/news/life/breakingnews/3649202"
# url = "https://en.wikipedia.org/wiki/Automatic_summarization"
parser = HtmlParser.from_url(url, Tokenizer(LANGUAGE))
summarizer = Summarizer(Stemmer(LANGUAGE))
summarizer.stop_words = get_stop_words(LANGUAGE)
sumies = summarizer(parser.document, SENTENCES_COUNT)
for i, sentence in enumerate(sumies):
    print("{}. {}".format(i + 1, sentence))


LANGUAGE = "chinese"
SENTENCES_COUNT = 5
parser = PlaintextParser.from_file("ch09/article1.txt", Tokenizer(LANGUAGE))
summarizer = Summarizer(Stemmer(LANGUAGE))
summarizer.stop_words = get_stop_words(LANGUAGE)
sumies = summarizer(parser.document, SENTENCES_COUNT)
for i, sentence in enumerate(sumies):
    print("{}. {}".format(i + 1, sentence))





from wordcloud import WordCloud
import matplotlib.pyplot as plt
import jieba
from collections import Counter
from PIL import Image
import numpy as np
import requests

text = open("ch09/travel.txt", "r", encoding="utf-8").read()
jieba.set_dictionary("ch09/dict.txt.big.txt")
with open("ch09/stopWord_cloud.txt", "r", encoding="utf-8-sig") as f:
# with open('ch09/stopWord_cloudmod.txt', 'r', encoding='utf-8-sig') as f:
    stops = f.read().split("\n")
    # Remove any empty strings that might appear from trailing newlines
    # stops = [word for word in stops if word.strip()]
terms = []
for t in jieba.cut(text, cut_all=False):
    # if t not in stops:
    if t.strip() and t not in stops: # Fix multiline issue
        terms.append(t)
diction = Counter(terms)
fontfile = requests.get(
    "https://drive.google.com/uc?id=1QdaqR8Setf4HEulrIW79UEV_Lg_fuoWz&export=download"
)
with open("taipei_sans_tc_beta.ttf", "wb") as f:
    f.write(fontfile.content)
wordcloud = WordCloud(font_path="taipei_sans_tc_beta.ttf")
# mask = np.array(Image.open("heart.png"))
# wordcloud = WordCloud(background_color="white",mask=mask,font_path='taipei_sans_tc_beta.ttf')
wordcloud.generate_from_frequencies(frequencies=diction)
plt.figure(figsize=(10, 10))
plt.imshow(wordcloud)
plt.axis("off")
plt.show()
wordcloud.to_file("bookCloud2.png")



